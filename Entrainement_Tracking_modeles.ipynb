{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ce notebook présente le suivi et l’évaluation des modèles de classification appliqués à la prédiction du défaut de paiement.\n",
    "Chaque modèle : Logistic Regression, Decision Tree et Random Forest est entraîné sur le même jeu de données et ses performances sont enregistrées avec MLflow.\n",
    "\n",
    "L’objectif de ce notebook est de :\n",
    "\n",
    "1) Démontrer la création et le suivi des experiments et runs MLflow pour chaque modèle\n",
    "2) Sauvegarder et visualiser les métriques de performance (accuracy, F1-score, précision) et les artefacts (matrices de confusion, importances des features).\n",
    "3) Identifier et sauvegarder le meilleur modèle selon le F1-score pour un usage ultérieur."
   ],
   "id": "97f6225771d8603b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Avant de lancer ce notebook : assurez-vous que le serveur MLflow est démarré dans le terminal :",
   "id": "8096e17445d1cad0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T17:34:43.339725Z",
     "start_time": "2025-10-16T17:34:39.793096Z"
    }
   },
   "cell_type": "code",
   "source": "!mlflow server --host 127.0.0.1 --port 8080",
   "id": "7ef752857233206a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bintoudiop/Documents/Dossier_École/Formation data analytics/MLOPS/Projet_MLOPS/venv/lib/python3.10/site-packages/mlflow/gateway/config.py:454: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\r\n",
      "  class Route(ConfigModel):\r\n",
      "\u001B[31mERROR\u001B[0m:    [Errno 48] Address already in use\r\n",
      "Running the mlflow server failed. Please see the logs above for details.\r\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import des librairies",
   "id": "57e6ba5626f9f486"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:19:41.184093Z",
     "start_time": "2025-10-17T19:19:41.168013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "73f98a6d3df00e3b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:19:43.440234Z",
     "start_time": "2025-10-17T19:19:43.431738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Connexion au serveur MLflow local\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "print(\"Connecté au serveur MLflow local : http://127.0.0.1:8080\")"
   ],
   "id": "8dc6821c5344108a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecté au serveur MLflow local : http://127.0.0.1:8080\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Configuration des chemins",
   "id": "5be913f6df0cb2ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:19:45.526270Z",
     "start_time": "2025-10-17T19:19:45.518646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"data\", \"loan_data_preprocessed.csv\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"Models\")\n",
    "MLARTIFACTS_DIR = os.path.join(BASE_DIR, \"mlartifacts\")\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(MLARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Répertoires prêts : {BASE_DIR}, {MODELS_DIR}, {MLARTIFACTS_DIR}\")"
   ],
   "id": "903c0e8b012f0bad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoires prêts : /Users/bintoudiop/Documents/Dossier_École/Formation data analytics/MLOPS/Projet_MLOPS, /Users/bintoudiop/Documents/Dossier_École/Formation data analytics/MLOPS/Projet_MLOPS/Models, /Users/bintoudiop/Documents/Dossier_École/Formation data analytics/MLOPS/Projet_MLOPS/mlartifacts\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Chargement et préparation des données",
   "id": "9f7389adab540f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:19:47.423592Z",
     "start_time": "2025-10-17T19:19:47.354939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n",
    "\n",
    "# Séparation features / target\n",
    "X = df[['credit_lines_outstanding', 'loan_amt_outstanding',\n",
    "          'total_debt_outstanding', 'income', 'years_employed', 'fico_score']]\n",
    "y = df[\"default\"]\n",
    "X = X.apply(pd.to_numeric, errors='coerce').astype(\"float64\")\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
   ],
   "id": "f9f8cd98ee6a89ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8000, 6), Test: (2000, 6)\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:19:49.656835Z",
     "start_time": "2025-10-17T19:19:49.623113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Les données sont désiquilibrées, on équilibre les classes\n",
    "print(\"\\n Vérification du déséquilibre \")\n",
    "counter = Counter(y_train)\n",
    "print(\"Avant rééchantillonnage :\", counter)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "counter_res = Counter(y_train_res)\n",
    "print(\"Après rééchantillonnage :\", counter_res)\n"
   ],
   "id": "6ef33d7702a36f90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Vérification du déséquilibre \n",
      "Avant rééchantillonnage : Counter({0: 6519, 1: 1481})\n",
      "Après rééchantillonnage : Counter({1: 6519, 0: 6519})\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Définition des modèles",
   "id": "12ec34f2c38a2015"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:19:52.300980Z",
     "start_time": "2025-10-17T19:19:52.295222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_name = \"\""
   ],
   "id": "33e9d015e0986178",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Entraînement et tracking MLflow",
   "id": "44b3414ae28ec07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:20:01.255035Z",
     "start_time": "2025-10-17T19:19:54.218766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, model in models.items():\n",
    "\n",
    "    artifact_path = os.path.join(MLARTIFACTS_DIR, name)\n",
    "    os.makedirs(artifact_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    try:\n",
    "        experiment_id = client.create_experiment(\n",
    "            name=name,\n",
    "            artifact_location=artifact_path\n",
    "        )\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        experiment = client.get_experiment_by_name(name)\n",
    "        experiment_id = experiment.experiment_id\n",
    "\n",
    "    mlflow.set_experiment(name)\n",
    "\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{name}_run\"):\n",
    "\n",
    "        # --- Pipeline complet ---\n",
    "        pipeline = ImbPipeline([\n",
    "            ('scaler', StandardScaler()),                 # Scale les données\n",
    "            ('oversample', RandomOverSampler(random_state=42)),  # Équilibre les classes\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        #  Prédictions\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "        #  Métriques train (console uniquement)\n",
    "        acc_train = accuracy_score(y_train, y_train_pred)\n",
    "        f1_train = f1_score(y_train, y_train_pred)\n",
    "        prec_train = precision_score(y_train, y_train_pred)\n",
    "        recall_train = recall_score(y_train, y_train_pred)\n",
    "        tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "        print(f\"\\n {name} : Métriques train \")\n",
    "        print(f\"Accuracy: {acc_train:.3f}, F1: {f1_train:.3f}, Precision: {prec_train:.3f}, Recall: {recall_train:.3f}\")\n",
    "        print(f\"Vrais positifs: {tp_train}, Vrais négatifs: {tn_train}, Faux positifs: {fp_train}, Faux négatifs: {fn_train}\")\n",
    "        if abs(f1_train - f1_score(y_test, y_test_pred)) > 0.05:\n",
    "            print(\" Signe possible d'overfitting\")\n",
    "        else:\n",
    "            print(\" Pas de signe d'overfitting évident\")\n",
    "\n",
    "        #  Métriques test (logging MLflow)\n",
    "        acc_test = accuracy_score(y_test, y_test_pred)\n",
    "        f1_test = f1_score(y_test, y_test_pred)\n",
    "        prec_test = precision_score(y_test, y_test_pred)\n",
    "        recall_test = recall_score(y_test, y_test_pred)\n",
    "        tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "        fpr_test = fp_test / (fp_test + tn_test)\n",
    "        fnr_test = fn_test / (fn_test + tp_test)\n",
    "        roc_auc_test = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:,1]) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        mlflow.log_param(\"model_name\", name)\n",
    "        mlflow.log_metric(\"accuracy\", acc_test)\n",
    "        mlflow.log_metric(\"f1_score\", f1_test)\n",
    "        mlflow.log_metric(\"precision\", prec_test)\n",
    "        mlflow.log_metric(\"recall_test\", recall_test)\n",
    "        mlflow.log_metric(\"vrais_positifs\", tp_test)\n",
    "        mlflow.log_metric(\"vrais_negatifs\", tn_test)\n",
    "        mlflow.log_metric(\"faux_positifs\", fp_test)\n",
    "        mlflow.log_metric(\"faux_negatifs\", fn_test)\n",
    "        mlflow.log_metric(\"taux_faux_positifs\", fpr_test)\n",
    "        mlflow.log_metric(\"taux_faux_negatifs\", fnr_test)\n",
    "        if roc_auc_test is not None:\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc_test)\n",
    "\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_test, y_test_pred)\n",
    "        fig, ax = plt.subplots(figsize=(6,5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "        plt.xlabel(\"Prédit\")\n",
    "        plt.ylabel(\"Réel\")\n",
    "        plt.title(f\"Matrice de confusion - {name}\")\n",
    "        plt.tight_layout()\n",
    "        cm_file = os.path.join(artifact_path, f\"confusion_matrix_{name}.png\")\n",
    "        plt.savefig(cm_file)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(cm_file)\n",
    "\n",
    "\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            importances = model.feature_importances_\n",
    "            fig, ax = plt.subplots(figsize=(7,5))\n",
    "            sns.barplot(x=X.columns, y=importances, ax=ax)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.title(f\"Feature Importance - {name}\")\n",
    "            plt.tight_layout()\n",
    "            feat_file = os.path.join(artifact_path, f\"feature_importance_{name}.png\")\n",
    "            plt.savefig(feat_file)\n",
    "            plt.close()\n",
    "            mlflow.log_artifact(feat_file)\n",
    "\n",
    "        #  Sauvegarde meilleur modèle\n",
    "        if f1_test > best_f1:\n",
    "            best_f1 = f1_test\n",
    "            best_model = pipeline\n",
    "            best_name = name\n",
    "\n",
    "            model_file = os.path.join(MODELS_DIR, f\"BestModel_{name}_{best_f1:.4f}.pkl\")\n",
    "            with open(model_file, \"wb\") as f:\n",
    "                pickle.dump(best_model, f)\n",
    "            print(f\"-> Nouveau meilleur modèle sauvegardé : {model_file}\")\n",
    "\n",
    "        #  Logging modèle complet\n",
    "        input_example = X_test.iloc[:1]\n",
    "        signature = infer_signature(X_test, pipeline.predict(X_test))\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            name=\"model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n"
   ],
   "id": "b3ace1c11f21ca04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LogisticRegression : Métriques train \n",
      "Accuracy: 0.995, F1: 0.987, Precision: 0.974, Recall: 1.000\n",
      "Vrais positifs: 1481, Vrais négatifs: 6479, Faux positifs: 40, Faux négatifs: 0\n",
      " Pas de signe d'overfitting évident\n",
      "-> Nouveau meilleur modèle sauvegardé : /Users/bintoudiop/Documents/Dossier_École/Formation data analytics/MLOPS/Projet_MLOPS/Models/BestModel_LogisticRegression_0.9920.pkl\n",
      "🏃 View run LogisticRegression_run at: http://127.0.0.1:8080/#/experiments/779486009998673081/runs/6e7099ab338c4ae49b7bc25ffc23a56a\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/779486009998673081\n",
      "\n",
      " DecisionTree : Métriques train \n",
      "Accuracy: 1.000, F1: 1.000, Precision: 1.000, Recall: 1.000\n",
      "Vrais positifs: 1481, Vrais négatifs: 6519, Faux positifs: 0, Faux négatifs: 0\n",
      " Pas de signe d'overfitting évident\n",
      "🏃 View run DecisionTree_run at: http://127.0.0.1:8080/#/experiments/326855897572357880/runs/e5fe57974f004a0eb93a0a564b5a58ac\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/326855897572357880\n",
      "\n",
      " RandomForest : Métriques train \n",
      "Accuracy: 1.000, F1: 1.000, Precision: 1.000, Recall: 1.000\n",
      "Vrais positifs: 1481, Vrais négatifs: 6519, Faux positifs: 0, Faux négatifs: 0\n",
      " Pas de signe d'overfitting évident\n",
      "🏃 View run RandomForest_run at: http://127.0.0.1:8080/#/experiments/440865324328565143/runs/a5f6abcd999a4382865663fb31547231\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/440865324328565143\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Résultat final",
   "id": "4e653872f0a252d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T19:20:05.957702Z",
     "start_time": "2025-10-17T19:20:05.946692Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Meilleur modèle : {best_name} avec F1-score = {best_f1:.4f}\")",
   "id": "c3687f8121d5dd37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur modèle : LogisticRegression avec F1-score = 0.9920\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Chaque modèle a été suivi et évalué avec MLflow avec métriques et artefacts centralisés.\n",
    "Le meilleur modèle, sélectionné selon le F1-score est la Logistic Regression qui présente les performances les plus équilibrées sur le jeu de test."
   ],
   "id": "10148f9ba53140e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
